{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([0])\n",
      "Number of nodes: 20\n",
      "Number of edges: 400\n",
      "Has isolated nodes: False\n",
      "Has self-loops: True\n",
      "Is undirected: True\n",
      "Number of features: 20\n",
      "Number of ADHD images 557\n",
      "Number of CONTROL images 439\n",
      "Total images 996\n",
      "Train-Validation Image Dataset Shape torch.Size([996, 4, 29, 29])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.nn.functional import normalize\n",
    "from functions import *\n",
    "\n",
    "#region <Define Directories>\n",
    "#from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "\n",
    "proj_dir = '/content/drive/MyDrive/3_Research_Related/ADHD_Research_Google_Colab'\n",
    "proj_dir = '/Users/yongjunlee/Library/CloudStorage/GoogleDrive-yongjun.lee5@gmail.com/My Drive/3_Research_Related/ADHD_Research_Google_Colab'\n",
    "# for GNN models with mutual information adj matrix\n",
    "mi_dir_adhd   = proj_dir + '/DATA/MI_TABLE/mi_adhd.npy'\n",
    "mi_dir_control   = proj_dir + '/DATA/MI_TABLE/mi_control.npy'\n",
    "\n",
    "# for GNN models with correlation adj matrix\n",
    "corr_dir_adhd   = proj_dir + '/DATA/CORR_TABLE/corr_adhd.npy'\n",
    "corr_dir_control   = proj_dir + '/DATA/CORR_TABLE/corr_control.npy'\n",
    "\n",
    "# for CNN model\n",
    "mi_dir_adhd_overlap = proj_dir + '/DATA/MI_TABLE/mi_adhd_overlap.npy'\n",
    "mi_dir_control_overlap = proj_dir + '/DATA/MI_TABLE/mi_control_overlap.npy'\n",
    "\n",
    "# save accuracy and trained models\n",
    "result_dir = proj_dir + '/DATA/RESULTS'\n",
    "model_dir = proj_dir + '/DATA/MODELS'\n",
    "\n",
    "epoch_adhd_dir = proj_dir + '/DATA/MI_TABLE/num_epoch_ADHD.npy'\n",
    "epoch_control_dir = proj_dir + '/DATA/MI_TABLE/num_epoch_CONTROL.npy'\n",
    "#endregion\n",
    "\n",
    "#region Create Graph Dataset from MI tables\n",
    "### Graph - Training/Validation\n",
    "## This dataset will be split into training set and validation set\n",
    "#  Load mutual information matrices\n",
    "ADHD_mi = np.load(mi_dir_adhd)\n",
    "CONTROL_mi = np.load(mi_dir_control)\n",
    "\n",
    "ADHD_corr = np.load(corr_dir_adhd)\n",
    "CONTROL_corr = np.load(corr_dir_control)\n",
    "\n",
    "#  Get number of epochs for each ADHD patient.\n",
    "epo_per_adhd = np.load(epoch_adhd_dir)\n",
    "epo_per_control = np.load(epoch_control_dir)\n",
    "\n",
    "# dataset contains list of lists. each list contains graph for each patient for each epoch.\n",
    "count=0\n",
    "dataset_graph = []\n",
    "for i in epo_per_adhd:\n",
    "    patient_mi = ADHD_mi[count:count+int(i),:,:]\n",
    "    patient_train_val_graph = getGraph(patient_mi, y=1)\n",
    "    dataset_graph.append(patient_train_val_graph)\n",
    "    count+=int(i)\n",
    "\n",
    "count=0\n",
    "for i in epo_per_control:\n",
    "    patient_mi = CONTROL_mi[count:count+int(i),:,:]\n",
    "    patient_train_val_graph = getGraph(patient_mi, y=0)\n",
    "    dataset_graph.append(patient_train_val_graph)\n",
    "    count+=int(i)\n",
    "#endregion\n",
    "\n",
    "#region Create Graph Test Set\n",
    "# Test set is created by taking the average value \n",
    "# of all mutual information tables for each patient.\n",
    "\n",
    "# For each patient, find mean value of all MI tables\n",
    "# Then create new test datapoint.\n",
    "adhd_test_mi = np.zeros((61,20,20))\n",
    "n=0\n",
    "for i, num_epo in enumerate(epo_per_adhd):\n",
    "    num_epo = int(num_epo)\n",
    "    adhd_test_mi[i, :, :]= np.mean(ADHD_mi[n:n+num_epo, : , : ])\n",
    "    n+=num_epo\n",
    "\n",
    "# same procedure for control group\n",
    "control_test_mi = np.zeros((60,20,20))\n",
    "n=0\n",
    "for i, num_epo in enumerate(epo_per_control):\n",
    "    num_epo = int(num_epo)\n",
    "    control_test_mi[i, :, :]= np.mean(CONTROL_mi[n:n+num_epo, : , : ])\n",
    "    n+=num_epo\n",
    "\n",
    "# getGraph function to turn this into a pyG graph data format\n",
    "adhd_test_graph = getGraph(adhd_test_mi, y=1)\n",
    "control_test_graph = getGraph(control_test_mi, y=0)\n",
    "\n",
    "test_graph = adhd_test_graph + control_test_graph\n",
    "# very important to shuffle. Unshuffled data does not learn.\n",
    "random.shuffle(test_graph)\n",
    "#endregion \n",
    "\n",
    "# This is the summary of graph data objects.\n",
    "# Graph constructed from the 1st 4 seconds of recording from 100th patient\n",
    "data = dataset_graph[100][1]\n",
    "print(f'Label: {data.y}')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Number of features: {data.num_node_features}')\n",
    "\n",
    "\n",
    "#region Create Image Dataset\n",
    "ADHD_mi_overlap = np.load(mi_dir_adhd_overlap)\n",
    "CONTROL_mi_overlap = np.load(mi_dir_control_overlap)\n",
    "\n",
    "n_ch = 4 # Motivated by R, G, B, Alpha channels\n",
    "(ADHD_epochs, channels, channels) = ADHD_mi_overlap.shape\n",
    "(CONTROL_epochs, channels, channels) = CONTROL_mi_overlap.shape\n",
    "\n",
    "# Number of images\n",
    "num_img_ADHD = int(ADHD_epochs/n_ch)\n",
    "num_img_CONTROL = int(CONTROL_epochs/n_ch)\n",
    "n_img = num_img_ADHD+num_img_CONTROL\n",
    "\n",
    "# Target dataset dimension\n",
    "img_data = np.zeros((n_img, n_ch, channels, channels))\n",
    "label = np.zeros(n_img)\n",
    "\n",
    "# select every 4 MI tables and assign it to img_data. This simply raises ADHD_mi_overlap's dimension by 1.\n",
    "for img in range(num_img_ADHD):\n",
    "    img_data[img, :, :, :] = ADHD_mi_overlap[n_ch*img:n_ch*(img+1), :, :]\n",
    "    label[img] = 1\n",
    "for img in range(num_img_CONTROL):\n",
    "    img_data[num_img_ADHD+img, :, :, :] = CONTROL_mi_overlap[n_ch*img : n_ch*(img+1), :, :]\n",
    "    label[num_img_ADHD+img] = 0\n",
    "\n",
    "# just like any other image dataset, all values are normalized to values between 0 and 1.\n",
    "for img in range(n_img):\n",
    "    for ch in range(n_ch):\n",
    "        img_data[img, ch, :, :] = (img_data[img, ch, :, :]) / (np.max(img_data[img, ch, :, :]))\n",
    "\n",
    "# TensorDataset class does not have in-built shuffle function.\n",
    "# list of integers upt to 995 is shuffled and used as an index to shuffle label and img_data.\n",
    "rand_idx = np.arange(996)\n",
    "np.random.shuffle(rand_idx)\n",
    "img_data = img_data[rand_idx, : , : , :]\n",
    "label = label[rand_idx]\n",
    "\n",
    "img_data = torch.Tensor(img_data)\n",
    "label = torch.Tensor(label)\n",
    "label = label.long() # loss function requires this\n",
    "dataset_image = TensorDataset(img_data, label) #  Dataset class construction\n",
    "#endregion\n",
    "\n",
    "print('Number of ADHD images',num_img_ADHD)\n",
    "print('Number of CONTROL images',num_img_CONTROL)\n",
    "print('Total images',n_img)\n",
    "print('Train-Validation Image Dataset Shape',img_data.shape)\n",
    "\n",
    "\n",
    "#region Create Image Test Set\n",
    "epo_per_adhd = np.load(epoch_adhd_dir)\n",
    "epo_per_control = np.load(epoch_control_dir)\n",
    "\n",
    "adhd_test_img = np.zeros((61,4,29,29))\n",
    "control_test_img = np.zeros((60,4,29,29))\n",
    "test_label = np.zeros(121)\n",
    "\n",
    "# since image data is 3 dimensional, there were several ways to average image for patient.\n",
    "n=0\n",
    "for i, n_epo_patient in enumerate(epo_per_adhd):\n",
    "    n_im_patient = int(n_epo_patient/n_ch)\n",
    "    im_patient = np.zeros((n_im_patient, 4, 29, 29))\n",
    "    for j in range(n_im_patient):\n",
    "        im_patient[j , : , : , :] = ADHD_mi_overlap[n+j*4 : n+(j+1)*4] # I found the images that would be in img_data.\n",
    "    adhd_test_img[i, :, :, :]= np.mean(im_patient, axis=0) # then averaged the images element-wise.\n",
    "    test_label[i]=1\n",
    "    n+=int(n_epo_patient)\n",
    "\n",
    "n=0\n",
    "print(n)\n",
    "for i, n_epo_patient in enumerate(epo_per_control):\n",
    "    n_im_patient = int(n_epo_patient/n_ch)\n",
    "    im_patient = np.zeros((n_im_patient, 4, 29, 29))\n",
    "    for j in range(n_im_patient):\n",
    "        im_patient[j , : , : , :] = CONTROL_mi_overlap[n+j*4 : n+(j+1)*4]\n",
    "    control_test_img[i, :, :, :]= np.mean(im_patient, axis=0)\n",
    "    n+=int(n_epo_patient)\n",
    "\n",
    "test_img = np.concatenate((adhd_test_img, control_test_img), axis = 0)\n",
    "\n",
    "# test set is shuffled in the same manner\n",
    "rand_idx = np.arange(121)\n",
    "np.random.shuffle(rand_idx)\n",
    "test_img = test_img[rand_idx, : , : , :]\n",
    "test_label = test_label[rand_idx]\n",
    "\n",
    "test_img = torch.Tensor(test_img)\n",
    "test_label = torch.Tensor(test_label)\n",
    "test_label = test_label.long()\n",
    "test_dataset_img = TensorDataset(test_img, test_label)\n",
    "#endregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_graph[1].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[  8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25\n",
      "  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43\n",
      "  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61\n",
      "  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
      "  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97\n",
      "  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115\n",
      " 116 117 118 119 120]\n",
      "[0 1 2 3 4 5 6 7]\n",
      "1\n",
      "[  0   1   2   3   4   5   6   7  16  17  18  19  20  21  22  23  24  25\n",
      "  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43\n",
      "  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61\n",
      "  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
      "  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97\n",
      "  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115\n",
      " 116 117 118 119 120]\n",
      "[ 8  9 10 11 12 13 14 15]\n",
      "2\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  23  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[16 17 18 19 20 21 22]\n",
      "3\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[23 24 25 26 27 28 29]\n",
      "4\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  37  38  39  40  41  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[30 31 32 33 34 35 36]\n",
      "5\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[37 38 39 40 41 42 43]\n",
      "6\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[44 45 46 47 48 49 50]\n",
      "7\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[51 52 53 54 55 56 57]\n",
      "8\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[58 59 60 61 62 63 64]\n",
      "9\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[65 66 67 68 69 70 71]\n",
      "10\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[72 73 74 75 76 77 78]\n",
      "11\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[79 80 81 82 83 84 85]\n",
      "12\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  93  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[86 87 88 89 90 91 92]\n",
      "13\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[93 94 95 96 97 98 99]\n",
      "14\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120]\n",
      "[100 101 102 103 104 105 106]\n",
      "15\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 114\n",
      " 115 116 117 118 119 120]\n",
      "[107 108 109 110 111 112 113]\n",
      "16\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113]\n",
      "[114 115 116 117 118 119 120]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader as CNNLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import models\n",
    "model_name = \"SAGE\"\n",
    "h_ch=20\n",
    "k_hop=4\n",
    "lr=0.9\n",
    "\n",
    "kf = KFold(n_splits=17, shuffle=False)\n",
    "for fold, (idx1, idx2) in enumerate(kf.split(dataset_graph)):\n",
    "    print(fold)\n",
    "    print(idx1)\n",
    "    print(idx2)\n",
    "\n",
    "    # Define model, optimizer, and loss function\n",
    "    if model_name == 'SAGE':\n",
    "        model = models.SAGE(hidden_channels=h_ch, k_hop=k_hop)\n",
    "    elif model_name == 'GCN':\n",
    "        model = models.GCN(hidden_channels=h_ch, k_hop=k_hop)\n",
    "    #elif model_name == 'DIFF':\n",
    "    #    model = DIFF(hidden_channels=h_ch, K=k_hop)\n",
    "    else:\n",
    "        model = models.CNN()\n",
    "    \n",
    "    #opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        opt = torch.optim.NAdam(model.parameters(), lr=lr, betas = (0.9,0.999), momentum_decay=0.004)\n",
    "        loss_fnc = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[2160, 20], edge_index=[2, 43200], y=[108], batch=[2160], ptr=[109])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "DataBatch(x=[260, 20], edge_index=[2, 5200], y=[13], batch=[260], ptr=[14])\n",
      "('x', tensor([[0.2222, 0.2222, 0.2222,  ..., 0.2222, 0.2222, 0.2222],\n",
      "        [0.2222, 0.2222, 0.2222,  ..., 0.2222, 0.2222, 0.2222],\n",
      "        [0.2222, 0.2222, 0.2222,  ..., 0.2222, 0.2222, 0.2222],\n",
      "        ...,\n",
      "        [0.1753, 0.1753, 0.1753,  ..., 0.1753, 0.1753, 0.1753],\n",
      "        [0.1753, 0.1753, 0.1753,  ..., 0.1753, 0.1753, 0.1753],\n",
      "        [0.1753, 0.1753, 0.1753,  ..., 0.1753, 0.1753, 0.1753]]))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m main_func(\u001b[39m\"\u001b[39;49m\u001b[39mSAGE\u001b[39;49m\u001b[39m\"\u001b[39;49m, dataset_graph, test_graph, model_dir, result_dir, \u001b[39m1\u001b[39;49m, \u001b[39m10\u001b[39;49m, \u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-yongjun.lee5@gmail.com/My Drive/3_Research_Related/ADHD_Research_Google_Colab/SCRIPT/2_python/functions.py:160\u001b[0m, in \u001b[0;36mmain_func\u001b[0;34m(model_name, dataset, test_dataset, model_dir, result_dir, k_hop, k_fold, n_epo, h_ch, lr, save)\u001b[0m\n\u001b[1;32m    158\u001b[0m     train_acc \u001b[39m=\u001b[39m test(model, train_loader, train_dataset)\n\u001b[1;32m    159\u001b[0m     valid_acc \u001b[39m=\u001b[39m test(model, valid_loader, valid_dataset)\n\u001b[0;32m--> 160\u001b[0m     test_acc \u001b[39m=\u001b[39m test(model, test_loader, test_dataset)\n\u001b[1;32m    162\u001b[0m list_train_acc\u001b[39m.\u001b[39mappend(train_acc)\n\u001b[1;32m    163\u001b[0m list_valid_acc\u001b[39m.\u001b[39mappend(valid_acc)\n",
      "File \u001b[0;32m~/Library/CloudStorage/GoogleDrive-yongjun.lee5@gmail.com/My Drive/3_Research_Related/ADHD_Research_Google_Colab/SCRIPT/2_python/functions.py:64\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, loader, dataset)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m patient:\n\u001b[1;32m     63\u001b[0m     \u001b[39mprint\u001b[39m(data)\n\u001b[0;32m---> 64\u001b[0m     out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39mbatch)\n\u001b[1;32m     65\u001b[0m     pred \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# make prediction based on returned softmax values\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((pred \u001b[39m==\u001b[39m data\u001b[39m.\u001b[39my)\u001b[39m.\u001b[39msum()) \u001b[39m# count correct predictions\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "main_func(\"SAGE\", dataset_graph, test_graph, model_dir, result_dir, 1, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
